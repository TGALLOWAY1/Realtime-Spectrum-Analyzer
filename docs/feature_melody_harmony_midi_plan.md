# Melody/Harmony → MIDI Feature Plan

## 1) Repo reconnaissance

### Current architecture snapshot
- **Stack/UI framework:** Vanilla browser app (`index.html` + `main.js`) with Tailwind via CDN. No React/Electron/SwiftUI layer.  
- **Audio pipeline:** Web Audio API (`AudioContext`, `AnalyserNode`, `MediaElementAudioSourceNode`) fed by an `<audio>` element that loads test files from local paths.  
- **Rendering pipeline:** Canvas 2D visualizations (spectrum, band visualizer, oscilloscope) driven by `requestAnimationFrame`.

### Answers to requested reconnaissance questions

1. **Where is audio loading/decoding handled?**
   - Audio is loaded through a dynamically created HTMLAudioElement in `setupTestAudio(audioPath)`.
   - It binds source URL, handles media errors/fallbacks (`.wav` → `.mp3`), and waits for `canplay/canplaythrough` before creating a `MediaElementAudioSourceNode`.
   - This means decoding is browser-managed via media element playback path, not explicit `decodeAudioData`.

2. **Where is FFT/spectrum computed?**
   - FFT bins are generated by `AnalyserNode` (`analyser.getFloatFrequencyData(fftData)`) inside `update()`.
   - Smoothing is then applied through `updateEMA` and used for spectrum + band rendering.

3. **What UI framework is used?**
   - Plain HTML + vanilla JS + Tailwind CSS utility classes loaded from CDN.

4. **How are audio buffers represented?**
   - Frequency-domain data: `Float32Array` (`fftData`, `smoothedData`) from `AnalyserNode`.
   - Time-domain data: `Float32Array` (`timeDomainData`) from analyser time-domain reads.
   - Waveform history is a JS array-backed circular buffer (`waveformBuffer`) containing numeric samples.
   - There is currently no persistent offline `AudioBuffer` analysis object in the code.

5. **Is there an existing worker/thread system for heavy compute?**
   - No worker/thread abstraction exists currently (no Web Workers detected).
   - All work executes on the main UI thread.

---

## 2) Proposed module boundaries

To keep offline transcription isolated from realtime visualization, introduce a separate analysis pipeline under `src/analysis/` (or `analysis/` if keeping flat structure):

- `analysis/types.js`
  - Shared data contracts (`AnalysisJobInput`, `NoteEvent`, `ChordEvent`, `AnalysisResult`, options).
- `analysis/preprocess.js`
  - Mono conversion, normalization, optional HPSS adapter/stub.
- `analysis/stft.js`
  - Offline STFT/chroma utilities independent of UI render loop.
- `analysis/transcription.js`
  - Note extraction + note tracking (polyphonic v1).
- `analysis/melody_harmony_split.js`
  - Heuristic separation into melody vs harmony notes.
- `analysis/chords.js`
  - Chord template scoring, smoothing, key estimation.
- `analysis/atonality.js`
  - Atonal score computation and threshold classification.
- `analysis/midi_export.js`
  - MIDI writer for melody/chords tracks.
- `analysis/entrypoint.js`
  - `analyzeSampleToMidi(input)` orchestration.
- `analysis/worker.js` (optional but recommended)
  - Web Worker wrapper for long-running offline compute.

UI integration should remain in `main.js` (or split into `ui/controls.js`) and call the analysis entrypoint with explicit input buffers.

---

## 3) Data types (proposed)

```ts
interface AnalysisOptions {
  doHPSS: boolean;
  extractMelody: boolean;
  extractHarmony: boolean;
  inferChords: boolean;
  detectAtonal: boolean;
  timeResolutionMs: number;      // default 20-50
  minNoteDurationMs: number;     // default 60-120
}

interface AnalysisJobInput {
  audioBuffer: Float32Array;     // mono PCM
  sampleRate: number;
  options: AnalysisOptions;
}

interface NoteEvent {
  pitchMidi: number;             // 0-127
  startSec: number;
  durationSec: number;
  velocity?: number;             // 0-127
  confidence: number;            // 0-1
}

interface ChordEvent {
  rootPitchClass?: number;       // 0-11
  rootMidi?: number;             // optional if needed for voicing
  quality: string;               // maj|min|dim|aug|sus2|sus4|7|maj7|min7|...
  startSec: number;
  durationSec: number;
  confidence: number;
  label: string;                 // e.g. "Am7"
}

interface AnalysisResult {
  notes: NoteEvent[];
  melodyNotes: NoteEvent[];
  harmonyNotes: NoteEvent[];
  chords: ChordEvent[];
  keyEstimate?: {
    tonicPitchClass: number;
    mode: 'major' | 'minor';
    confidence: number;
    label: string;
  };
  atonalScore: number;           // 0-1
  isAtonal: boolean;
  debug?: {
    frameTimesSec?: number[];
    chroma?: number[][];
    chordWindowScores?: Array<Record<string, number>>;
    warnings?: string[];
  };
}
```

Public entrypoint:

```ts
async function analyzeSampleToMidi(input: AnalysisJobInput): Promise<AnalysisResult>
```

---

## 4) Performance constraints

- **Do not regress realtime analyzer FPS:** offline analysis must not block animation loop.
- **Target runtime:** ~30s clip should complete in a few seconds on modern laptop browsers for v1 heuristics.
- **Memory:** avoid retaining full-resolution intermediate matrices when possible; expose debug output only when requested.
- **Threading:** prefer Web Worker execution for STFT/chroma/note tracking; fallback to chunked main-thread processing if worker unavailable.

---

## 5) UX placement proposal

Add a new “Offline Analysis” section below existing controls:

- File/sample selector reused from existing audio source control.
- Buttons:
  - `Analyze Sample`
  - `Export MIDI` (disabled until result available)
- Toggles:
  - `Extract Melody`
  - `Infer Chords`
  - `HPSS`
  - `Detect Atonal`
- Status row:
  - progress indicator (queued/running/completed/error)
  - cancel action while running
- Visual overlays:
  - chord labels aligned to timeline
  - minimal piano-roll strip for melody/harmony notes
- Result summary:
  - key estimate + confidence
  - atonal/no-stable-key badge when `isAtonal = true`

---

## 6) Incremental delivery plan

1. **Data model + entrypoint skeleton** (no DSP changes).
2. **Preprocessing** (mono/normalize + HPSS stub).
3. **Transcription v1** (STFT → chroma → note events).
4. **Melody/harmony split** heuristics.
5. **Chord inference + key estimate**.
6. **Atonality scoring**.
7. **MIDI export**.
8. **UI integration** (analyze/export + overlays).
9. **Tests** (chord scoring/merging + MIDI golden checks).

This sequence isolates risk and keeps existing realtime analyzer behavior untouched.
